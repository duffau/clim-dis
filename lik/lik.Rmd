---
title: "Principles of likelihood-based inference"
author: "Edward Ionides"
date: "07/03/2015"
output:
  html_document:
    theme: flatly
    toc: yes
bibliography: lik.bib
csl: ecology.csl

---

Licensed under the Creative Commons attribution-noncommercial license, http://creativecommons.org/licenses/by-nc/3.0/.
Please share and remix noncommercially, mentioning its origin.  
![CC-BY_NC](http://dept.stat.lsa.umich.edu/~ionides/tutorials/cc-by-nc.png)

```{r opts,include=FALSE}
library(pomp)
library(knitr)
prefix <- "lik"
opts_chunk$set(
  progress=TRUE,
  prompt=FALSE,tidy=FALSE,highlight=TRUE,
  strip.white=TRUE,
  warning=FALSE,
  message=FALSE,
  error=FALSE,
  echo=TRUE,
  cache=TRUE,
  results='markup',
  fig.show='asis',
  size='small',
  fig.lp="fig:",
  fig.path=paste0("figure/",prefix,"-"),
  cache.path=paste0("cache/",prefix,"-"),
  fig.pos="h!",
  fig.align='center',
  fig.height=4,fig.width=6.83,
  dpi=300,
  dev='png',
  dev.args=list(bg='transparent')
  )

options(
  pomp.cache=getwd(),
  keep.source=TRUE,
  encoding="UTF-8"
  )

library(ggplot2)
theme_set(theme_bw())
```
# Session 4. Theory and practice of likelihood-based inference

## Objectives

1. Understand the basic techniques of likelihood-based inference

2. Describe how to apply these techniques in situations where the likelihood cannot be written down explicitly but can be evaluated and maximized via Monte Carlo methods.

3. Gain some experience at carrying out likelihood-based inferences for dynamic models using simulation-based statistical methodology in the R package 'pomp'.

# 4A. Principles of likelihood-based inference

## Definition of the likelihood function

Data are a sequence of $N$ observations, denoted $y_{1:N}^*$. A statistical model is a density function $f(y_{1:N};\theta)$ which defines a probability distribution for each value of a parameter vector $\theta$. Statistical inference involves deciding for which (if any) values of $\theta$ it is reasonable to model $y_{1:N}^*$ as a random draw from $f(y_{1:N};\theta)$.

The likelihood function is the density function evaluated at the data. It is usually convenient to work with the log likelihood function,
$$\ell(\theta)=\log f(y_{1:N}^*;\theta)$$


### Modeling using discrete and continuous distributions

Recall that the probability distribution $f(y_{1:N};\theta)$ defines a random variable $Y_{1:N}$ for which probabilities can be computed as integrals of $f(y_{1:N};\theta)$. Specifically, for any event $E$ describing a set of possible outcomes of $Y_{1:N}$, 
$$P[\mbox{$Y_{1:N}$ is in $E$}] = \int_E f(y_{1:N}^*;\theta)\, dy_{1:N}.$$ 
If the model corresponds to a discrete distribution, then the integral is replaced by a sum and the probability density function is called a probability mass function. The definition of the likelihood function remains unchanged. We will use the notation of continuous random variables, but all the methods apply also to discrete models. 

### Indirect specification of the statistical model via a simulation procedure

* For simple statistical models, we may describe the model by explicitly writing the density function $f(y_{1:N};\theta)$. One may then ask how to simulate a random variable $Y_{1:N}\sim f(y_{1:N};\theta)$.

* For many dynamic models it is convenient to define the model via a procedure to simulate the random variable $Y_{1:N}$. This implicitly defines the corresponding density $f(y_{1:N};\theta)$. For a complicated simulation procedure, it may be difficult or impossible to write down $f(y_{1:N};\theta)$ exactly. 

* It is important for us to bear in mind that the likelihood function exists even when we don't know what it is! We can still talk about the likelihood function, and develop numerical methods that take advantage of its statistical properties.

## Maximizing the likelihood over all parameters or a subset of the parameters

Call the whole parameter space $\Theta$. Let $\Theta^*$ be a subset of $\Theta$, constraining parameters to describe scientific hypotheses of interest. For example, in a disease transmission model, $\Theta^*$ could assert that the probability of a case being reported is $\rho=0.8$.

* We define the maximized log likelihood for $\Theta$ and $\Theta^*$ to be
$$\ell_\mathrm{max}=\max\{\ell(\theta), \mbox{$\theta$ in $\Theta$}\},\quad
\ell^*_\mathrm{max}=\max\{\ell(\theta), \mbox{$\theta$ in $\Theta^*$}\}.$$

* Intuitively, a model with a higher maximized likelihood should be preferable to a model with a substantially lower maximized likelihood. 

* However, since $\Theta^*$ is a subset of $\Theta$, it is mathematically necessary that
$$ \ell_\mathrm{max} > \hat\ell^*_\mathrm{max}.$$
This raises the question of how close $\ell^*_\mathrm{max}$ should be to $\ell_\mathrm{max}$ to make it reasonable to prefer the simpler model $\Theta^*$ over the more complex model $\Theta$.

* The principle of parsimony (Occam's razor) advocates  scientists to be satisfied with the simpler model unless there is good evidence to do otherwise. So, for a formal hypothesis test, we set our null hypothesis to be $\Theta^*$ and our alternative hypothesis to be $\Theta$.

* A likelihood ratio test rejects $\Theta^*$ in favor of $\Theta$ when 
$$ \ell_\mathrm{max} -\ell_\mathrm{max}^* > c.$$

* An elegant mathematical property (Wilks' theorem) says that, for regular parametric models where $N$ is large and $\Theta$ has $d$ more free parameters than $\Theta^*$, then $2(\ell_\mathrm{max}-\ell^*_\mathrm{max})$ has a chi-square distribution with $d$ degrees of freedom.

* For the concrete situation where $\Theta^*$ fixes a single parameter, $d=1$, and we look for a test of size $0.05$, this suggests we reject $\Theta^*$ if
$$\ell_\mathrm{max} - \ell^*_\mathrm{max} > 1.92$$
since $P[\chi^2_1>3.84]=0.05$.

* One can carry out a simulation study to assess the actual size of this test, if one is concerned whether the asymptotic property of Wilks is sufficiently accurate. Fortunately, Wilks' theorem is often a good approximation for many finite-sample problems.

* Wilks' theorem gives a convenient, quick scientific interpretation of maximized log likelihood values. One can choose later whether to refine the interpretation via further simulation studies. 

* Akaike's information criterion (AIC) is defined by
$$AIC = -2(\mbox{maximized log likelihood}) +2(\mbox{\# parametes}).$$
This criterion makes a slightly different decision, recommending $\Theta$ over $\Theta^*$ if
$$\ell_\mathrm{max} -\ell_\mathrm{max}^* > d.$$
The justification of AIC is based on minimizing prediction error. AIC tends to prefer larger models than Occam's razor: heuristically, it does not value simplicity for its own sake, but only because unnecessary parameters lead to over-fitting and hence greater out-of-fit forecasting error. 

* Wilks' theorem applies only to nested hypotheses (when $\Theta^*$ is a subset of $\Theta$) whereas AIC is applicable to compare non-nested models, which may have entirely different structure. 

* Although AIC is not designed to be a formal statistical test, it is a commonly used objective rule for model selection. This rule could be intrepreted as a hypothsis test, with the size and power investigated by simulation, if desired.

#### Exercise: determine the size of AIC as a hypothesis test for nested hypotheses with $d=1$ in a regular parametric situation. 

## Confidence intervals for parameters: Profile likelihood

The likelihood ratio test with $d=1$ gives a good way to construct confidence intervals. Suppose we are interested in a specific parameter, $\phi$, and we want to consider whether the data support a possibility that $\phi=\phi^*$ in the absence of assumptions on the other parameters. Then, we can take $\Theta^*$ to be the subset of $\Theta$ satisfying $\phi=\phi^*$. Using the chi-square approximation to the likelihood ratio statistic, a 95% confidence interval for $\phi$ consists of all the values $\phi^*$ for which
$$\ell_\mathrm{max}-\ell_\mathrm{max}^* < 1.92.$$

A way to vizualize the information about a specific parameter $\phi$ is via the profile likelihood function, defined as 
$$\ell_\mathrm{profile}(\phi^*) = \max\{\mbox{$\ell(\theta)$ subject to the constraint $\phi=\phi^*$}\}.$$
We then plot $\ell_\mathrm{profile}(\phi)$ against $\phi$. 

* The set of values of $\phi$ for which $\ell_\mathrm{profile}(\phi)$ lies above a horizontal line with $y$-axis value $\ell_\mathrm{max}-c$ gives an approximate confidence interval (using Wilks' theorem) with confidence level given by
$P[\chi^2_1<2c]$.

* The maximum of $\ell_\mathrm{profile}(\phi)$ over all values of $\phi$ is $\ell_\mathrm{max}$.

* Thus, a profile plot allows us to visualize an entire spectrum of confidence intervals. 

* If the profile plot has two peaks (i.e., $\ell_\mathrm{profile}(\phi)$ is bimodal) then a likelihood ratio test helps us to assess whether or not both peaks provide adequate explanations of the data.

## The graph of the likelihood function: The likelihood surface

* Intuitively, it can be helpful to think of the geometric surface defined by the likelihood function. 

* If $\Theta$ is two-dimensional, then the surface $\ell(\theta)$ has features like a landscape. 

** Local maxima of $\ell(\theta)$ are peaks

** local minima are valleys

** peaks may be separated by a valley or may be joined by a ridge. If you go along the ridge, you may be able to go from one peak to the other without losing much elevation. Narrow ridges can be easy to fall off, and hard to get back on to.

* In higher dimensions, one can still think of peaks and valleys and ridges. However, as the dimension increases it quickly becomes hard to imagine the surface.

## Point estimates for parameters: The maximum likelihood estimate (MLE)

We define maximum likelihood estimates (MLEs) $\hat\theta$ and $\hat\theta^*$ such that
$$\ell(\hat\theta)=\ell_\mathrm{max},\quad \ell(\hat\theta^*)=\ell_\mathrm{max}^*.$$

* If the likelihood function has a flat region, or ridge, at its maximum then the MLE is not unique. Alternatively, one can talk about a maximum likelihood surface describing the set of parameter values for which $\ell(\hat\theta)=\ell_\mathrm{max}$.

* Flat, or nearly flat, ridges in the likelihood surface are not just an idle concern. Many dynamic models have some combination of parameters that is weakly identified, meaning that it cannot be well estimated from the available data.

### Biological interpretation of parameter estimates

When we write down a mechanistic model for an epidemiological system, we have some idea of what we intend parameters to mean; a reporting rate, a contact rate between individuals, an immigration rate, a duration of immunity, etc. 

* The data and the parameter estimation procedure do not know about our intended interpretation of the model. It can and does happen that some parameter estimates statistically consistent with the data may be scientifically absurd according to the biological reasoning that went into building the model. 

* This can arise as a consequence of weak identifiability. 

* It can also be a warning that the data do not agree that our model represents reality in the way we had hoped. Perhaps more work is needed on model development.

* Biologically unreasonable parameter estimates can sometimes be avoided by fixing some parameters at known, reasonable values. However, this risks suppressing the warning that the data were trying to give about weaknesses in the model, or in the biological interpretation of it.

* This issue will be discussed further when it arises in case studies.




