---
title: "Case study: Measles in large and small towns"
author: "Aaron A. King"
date: "2015-07-07"
output:
  html_document:
    theme: flatly
    toc: yes
bibliography: ../sbied.bib
csl: ../ecology.csl

---

\newcommand\prob[1]{\mathbb{P}\left[{#1}\right]}
\newcommand\expect[1]{\mathbb{E}\left[{#1}\right]}
\newcommand\var[1]{\mathrm{Var}\left[{#1}\right]}
\newcommand\dist[2]{\mathrm{#1}\left(#2\right)}
\newcommand\dlta[1]{{\Delta}{#1}}
\newcommand\scinot[2]{$#1 \times 10^{#2}$\xspace}
\newcommand{\mortality}{m}
\newcommand{\birth}{b}
\newcommand{\loglik}{\ell}
\newcommand{\immigration}{\iota}
\newcommand{\amplitude}{a}
\newcommand{\cohort}{c}
\newcommand{\R}{\textsf{R}}
\newcommand{\Rzero}{{R_0}}

Licensed under the Creative Commons attribution-noncommercial license, http://creativecommons.org/licenses/by-nc/3.0/.
Please share and remix noncommercially, mentioning its origin.  
![CC-BY_NC](http://kinglab.eeb.lsa.umich.edu/graphics/cc-by-nc.png)
Produced in R version `r getRversion()` using `pomp` version `r packageVersion("pomp")`.

In this example, we revisit the analysis of @He2010.
This is intended to be a concrete example of a full data analysis.
Whilst @He2010 examined measles in 20 cities, we will focus on London alone.

```{r knitr-opts,include=FALSE,cache=FALSE,purl=FALSE}
library(knitr)
prefix <- "measles"
opts_chunk$set(
  progress=TRUE,
  prompt=FALSE,tidy=FALSE,highlight=TRUE,
  strip.white=TRUE,
  warning=FALSE,
  message=FALSE,
  error=FALSE,
  echo=TRUE,
  cache=TRUE,
  results='markup',
  fig.show='asis',
  size='small',
  fig.lp="fig:",
  fig.path=paste0("figure/",prefix,"-"),
  cache.path=paste0("cache/",prefix,"-"),
  fig.pos="h!",
  fig.align='center',
  fig.height=4,fig.width=6.83,
  dpi=300,
  dev='png',
  dev.args=list(bg='transparent')
  )
```
```{r opts,include=FALSE,cache=FALSE}
options(
  keep.source=TRUE,
  stringsAsFactors=FALSE,
  encoding="UTF-8",
  pomp.cache="cache"
  )

require(pomp)
require(magrittr)
require(plyr)
require(reshape2)
require(ggplot2)
theme_set(theme_bw())

line.color <- "red"
plot.color <- "black"

set.seed(1109529108L)
```


----------------------------------

## Measles revisited

### Challenges & motivation

- Understanding, forecasting, managing epidemiological systems increasingly depends on models
- Increasing interest in opening up the black box: mechanistic models
- Real epidemiological systems:
    - are nonlinear
    - are stochastic
    - are nonstationary
	  - evolve in continuous time
	  - have hidden variables
	  - can be measured only with (large) error
- Dynamics of infectious disease outbreaks illustrate this well

```{r all-data-plot,echo=FALSE}
load("twentycities.rda")
measles %>% 
  subset(town %in% c("London","Liverpool","Hastings")) %>%
  ggplot(aes(x=date,y=cases))+
  geom_line()+
  facet_grid(town~.,scales='free_y')+
  labs(y="weekly cases")
```

----------------------------------

### Outline

- revisit classic measles data set
- use a model that 
    1. expresses our current understanding of measles dynamics
    1. cannot be fit by existing likelihood-based methods
- examine data from large and small towns using the same model
- does our perspective on this disease change?
- what bigger lessons can we learn regarding inference for dynamical systems?

----------------------------------

### @He2010

#### Data sets

  - Twenty towns 
	- population sizes: 2k--3.4M
	- Weekly case reports, 1950--1963
	- Annual birth records and population sizes, 1944--1963

```{r map,echo=FALSE}
# require(maps)
# with(map("world","UK",plot=FALSE),data.frame(long=x,lat=y)) %>%
#   subset(long>-7 & long < 3 & lat > 49 & lat < 58) -> GB
# read.csv("data/GB_Coast.csv") %>%
#   rename(c(Long="long",Lat="lat")) -> GB
require(ggmap)
ggmap(get_map(c(-4,54),zoom=6,scale=2,source="google",maptype="satellite"))+
# ggplot(data=GB,aes(x=long,y=lat))+
  geom_point(data=coord,aes(x=long,y=lat),color='red',alpha=1)+
  # geom_text(data=coord,aes(x=long,y=lat,label=town),vjust=0,size=2,col='white')+
  # geom_path()+
  # coord_map(projection="gall",lat0=54)+
  labs(x="",y="")+
  theme_nothing()
#   theme(panel.border=element_blank(),axis.ticks=element_blank(),
#         axis.text=element_blank())
```
 
```{r dataplot,echo=FALSE,fig.height=10}
demog %>% ddply(~town,summarize,mean.pop=mean(pop)) %>%
  arrange(mean.pop) -> meanpop
measles %>%
  mutate(town=ordered(town,levels=meanpop$town)) %>%
  ggplot(aes(x=date,y=cases))+
  geom_line()+
  scale_y_continuous(breaks=c(0,4,40,400,4000),trans=scales::log1p_trans())+
  facet_wrap(~town,ncol=4)
```

---------------------------------------


#### Continuous-time Markov process model

```{r seir-diagram1,echo=FALSE,cache=FALSE}
require(DiagrammeR)
DiagrammeR("digraph SEIR {
  graph [rankdir=TD, overlap=false, fontsize = 10]
  node[shape=egg, label='B'] b;
  subgraph {
    rank=same;
    node[shape=oval, label='S'] S;
    node[shape=oval, label='E'] E;
    node[shape=oval, label='I'] I;
    node[shape=oval, label='R'] R;
    S->E E->I I->R
  }
  node[shape=diamond, label='dead'] d;
  b->S
  {S E I R}->d
   }",type="grViz",engine="dot",height=300,width=500)
```

- $B(t) = \text{birth rate, from data}$
- $N(t) = \text{population size, from data}$
- $\mathrm{cases}_t\,\vert\,I{\to}R=z_t \sim \mathrm{normal}\left(\rho\,z_t,\rho\,(1-\rho)\,z_t+(\psi\,\rho\,z_t)^2\right)$

- entry into susceptible class:
$$\mu_{BS}(t) = (1-c)\,B(t-\tau)+c\,\delta(t-t_0)\,\int_{t-1}^{t}\,B(t-\tau-s)\,ds$$

- force of infection
$$\mu_{SE}(t) = \tfrac{\beta(t)}{N(t)}\,(I+\iota)\,\zeta(t)$$

- $c = \text{cohort effect}$  
- $\tau = \text{school-entry delay}$  
- $\beta(t) = \text{school-term transmission}$  
- $\iota = \text{imported infections}$
- $\zeta(t) = \text{white noise with intensity}\,\sigma_{SE}$


---------------------------------------

#### Fitting procedure

- a large Latin-hypercube design was used to initiate searches
- iterated filtering to maximize the likelihood
- point estimates of all parameters for 20 cities
- profile likelihoods to quantify uncertainty in London and Hastings

---------------------------------------


#### Imported infections

$$\mu_{SE}=\frac{\beta(t)}{N(t)}\,(I+\iota)\,\zeta(t)$$

```{r imports,results="hide",echo=FALSE}   
best <- read.csv('data/iota.csv',row.names=1)

op <- par(
          font=2,
          fig=c(0,1,0,1),
          mar=c(4,4,4,4),
          bty='l'
          )
plot.new()
mtext(side=2,line=2.5,text="profile log likelihood",adj=0.5)
mtext(side=1,line=2,text=expression(paste("imported infections, ",iota)),adj=0.5)

x <- best[grep('London',rownames(best)),]
fit <- loess(loglik~log(iota),data=x,span=0.7)
nd <- data.frame(iota=with(x,exp(seq(from=min(log(iota)),to=max(log(iota)),length=100))))
nd$loglik <- predict(fit,newdata=nd)
cutoff <- max(nd$loglik,na.rm=T)-0.5*qchisq(p=0.95,df=1)
conf.int <- range(nd$iota[nd$loglik>cutoff],na.rm=T)
par(fig=c(0,1,0.5,1),mar=c(0.5,4,4,4),new=T)
plot(
     loglik~iota,
     data=x,
     font=2,
     bty='l',
     ann=F,
     xaxt='n',
     log='x',
     xlim=c(0.001,100),
     ylim=max(x$loglik)+c(-15,1)
     )
axis(side=1,at=c(0.001,0.005,0.01,0.05,0.1,0.5,1,5,10,50,100),labels=F)
lines(loglik~iota,data=nd,col=line.color)
abline(h=cutoff,lty='33')
abline(v=conf.int,lty='63')
text(0.002,cutoff,"London",pos=3)

x <- best[grep('Hastings',rownames(best)),]
fit <- loess(loglik~log(iota),data=x,span=0.7)
nd <- data.frame(iota=with(x,seq(from=min(iota),to=max(iota),length=100)))
nd$loglik <- predict(fit,newdata=nd)
cutoff <- max(nd$loglik,na.rm=T)-0.5*qchisq(p=0.95,df=1)
conf.int <- range(nd$iota[nd$loglik>cutoff],na.rm=T)
par(fig=c(0,1,0,0.5),mar=c(4,4,0.5,4),new=T)
plot(
     loglik~iota,
     data=x,
     font=2,
     bty='l',
     ann=F,
     xaxt='n',
     log='x',
     xlim=c(0.001,100),
     ylim=max(x$loglik)+c(-15,1)
     )
axis(
     side=1,
     at=c(0.001,0.005,0.01,0.05,0.1,0.5,1,5,10,50,100),
     labels=c(expression(10^-3),"",expression(10^-2),"",expression(10^-1),"",expression(10^0),"",expression(10^1),"",expression(10^2))
     )
lines(loglik~iota,data=nd,col=line.color)
abline(h=cutoff,lty='33')
abline(v=conf.int,lty='63')
text(0.002,cutoff,"Hastings",pos=3)
par(op)
```

---------------------------------------


#### Seasonality

```{r amplitude,echo=FALSE,results="hide"}   
 
best <- read.csv('data/amplitude.csv',row.names=1)

op <- par(
          font=2,
          fig=c(0,1,0,1),
          mar=c(4,4,4,4),
          bty='l'
          )
plot.new()
mtext(side=2,line=2.5,text="profile log likelihood",adj=0.5)
mtext(side=1,line=2,text="amplitude of term-time seasonality",adj=0.5)

x <- best[grep('London',rownames(best)),]
fit <- loess(loglik~amplitude,data=x,span=0.7)
nd <- data.frame(amplitude=with(x,seq(from=min(amplitude),to=max(amplitude),length=100)))
nd$loglik <- predict(fit,newdata=nd)
cutoff <- max(nd$loglik,na.rm=T)-0.5*qchisq(p=0.95,df=1)
conf.int <- range(nd$amplitude[nd$loglik>cutoff],na.rm=T)
par(fig=c(0,1,0.5,1),mar=c(0.5,4,4,4),new=T)
plot(
     loglik~amplitude,
     data=x,
     font=2,
     bty='l',
     ann=F,
     xaxt='n',
     xlim=c(0,1),
     ylim=max(x$loglik)+c(-10,1)
     )
axis(side=1,at=seq(0,1,by=0.2),labels=F)
lines(loglik~amplitude,data=nd,col=line.color)
abline(h=cutoff,lty='33')
abline(v=conf.int,lty='63')
text(0.9,cutoff,"London",pos=3)

x <- best[grep('Hastings',rownames(best)),]
fit <- loess(loglik~amplitude,data=x,span=0.7)
nd <- data.frame(amplitude=with(x,seq(from=min(amplitude),to=max(amplitude),length=100)))
nd$loglik <- predict(fit,newdata=nd)
cutoff <- max(nd$loglik,na.rm=T)-0.5*qchisq(p=0.95,df=1)
conf.int <- range(nd$amplitude[nd$loglik>cutoff],na.rm=T)
par(fig=c(0,1,0,0.5),mar=c(4,4,0.5,4),new=T)
plot(
     loglik~amplitude,
     data=x,
     font=2,
     bty='l',
     ann=F,
     xaxt='n',
     xlim=c(0,1),
     ylim=max(x$loglik)+c(-10,1)
     )
axis(side=1,at=seq(0,1,by=0.2))
lines(loglik~amplitude,data=nd,col=line.color)
abline(h=cutoff,lty='33')
abline(v=conf.int,lty='63')
text(0.9,cutoff,"Hastings",pos=3)
par(op)
```

---------------------------------------

### Notable findings

#### Parameter estimates

```{r esttable,echo=FALSE}
load("twentycities.rda")
mean.euler <- function(rate,dt=1/365) dt/(1-exp(-rate*dt))

demog %>% 
  subset(year==1950,select=c(town,pop)) -> pop
readRDS("He2010_mles.rds") %>%
  join(pop,by='town',type='left') %>%
  mutate(IP=365*mean.euler(gamma),
         LP=365*mean.euler(sigma)) %>%
  arrange(pop) %>%
  subset(select=c(town,pop,R0,amplitude,LP,IP,alpha,iota,rho,psi,sigmaSE)) -> est

est %>% melt(id=c("town","pop")) %>%
  ddply(~variable,summarize,cor=cor(log(value),log(pop),
                                    use='all.obs',method='spearman')) -> cors
cors <- setNames(cors$cor,cors$variable)

tab <- est
rownames(tab) <- tab$town
tab$town <- NULL

kable(signif(rbind(tab,r=cors[names(tab)]),3))
```

$r = \mathrm{cor}(\log{\hat\theta},\log{N_{1950}})$

---------------------------------------

#### Extrademographic stochasticity


$$\mu_{SE}=\frac{\beta(t)}{N(t)}\,(I+\iota)\,\zeta(t)$$

```{r env-noise,echo=FALSE,results="hide"}
best <- read.csv('data/env_noise.csv',row.names=1)
mean.euler <- function(rate,dt=1/365) dt/(1-exp(-rate*dt))
best$IP <- mean.euler(best[,'gamma'])*365
best$LP <- mean.euler(best[,'sigma'])*365
best$sigSE <- 1.0/sqrt(best[,'eta'])

op <- par(
          font=2,
          fig=c(0,1,0,1),
          mar=c(4,4,4,4)
          )
plot.new()
mtext(side=1,line=2,text=expression(sigma[SE]),adj=0.5)
mtext(side=2,line=2.5,text="profile log likelihood",adj=0.5)
mtext(side=4,line=2.5,text="duration (days)",adj=0.5)

x <- best[grep('London',rownames(best)),]

fit <- loess(loglik~sigSE,data=x,span=0.7)
nd <- data.frame(sigSE=with(x,seq(from=min(sigSE),to=max(sigSE),length=100)))
nd$loglik <- predict(fit,newdata=nd)
fit <- loess(IP~sigSE,data=x,span=0.7)
nd$IP<-predict(fit,newdata=nd)
fit <- loess(LP~sigSE,data=x,span=0.7)
nd$LP<-predict(fit,newdata=nd)
cutoff <- max(nd$loglik,na.rm=T)-0.5*qchisq(p=0.95,df=1)
ci.lond <- conf.int <- range(nd$sigSE[nd$loglik>cutoff],na.rm=T)

par(fig=c(0,1,0.5,1),mar=c(0.5,4,4,4),new=T)
plot(
     loglik~sigSE,
     data=x,
     bty='u',
     ann=F,
     xaxt='n',
     yaxt='n',
     log='x',
     xlim=c(0.005,0.5),
     ylim=max(x$loglik)+c(-10,1)
     )
axis(side=1,at=c(0.005,0.01,0.02,0.05,0.1,0.2,0.5),labels=F)
axis(side=2)
lines(loglik~sigSE,data=nd,col=line.color)
abline(h=cutoff,lty='33')
abline(v=conf.int,lty='63')

IPcol='red'
LPcol='blue'
IPlty=1
LPlty=1
plot.window(xlim=c(0.005,0.5),ylim=c(0,20))
lines(IP~sigSE,data=nd,lwd=2,col=IPcol,lty=IPlty)
lines(LP~sigSE,data=nd,lwd=2,col=LPcol,lty=LPlty)
axis(side=4)

plot.window(xlim=c(1,10),ylim=c(0,1))
text(10^(0.9),0.8,"London",pos=3)
legend("topleft",lwd=2,col=c(IPcol,LPcol),
   lty=c(IPlty,LPlty),legend=c("IP","LP"),bty='n',bg='white')


x <- best[grep('Hastings',rownames(best)),]

fit <- loess(loglik~sigSE,data=x,span=0.7)
nd <- data.frame(sigSE=with(x,seq(from=min(sigSE),to=max(sigSE),length=100)))
nd$loglik <- predict(fit,newdata=nd)
fit <- loess(IP~sigSE,data=x,span=0.7)
nd$IP<-predict(fit,newdata=nd)
fit <- loess(LP~sigSE,data=x,span=0.7)
nd$LP<-predict(fit,newdata=nd)
cutoff <- max(nd$loglik,na.rm=T)-0.5*qchisq(p=0.95,df=1)
ci.hast <- conf.int <- range(nd$sigSE[nd$loglik>cutoff],na.rm=T)

par(fig=c(0,1,0,0.5),mar=c(4,4,0.5,4),new=T)
plot(
     loglik~sigSE,
     data=x,
     bty='l',
     ann=F,
     xaxt='n',
     yaxt='n',
     log='x',
     bty='u',
     xlim=c(0.005,0.5),
     ylim=max(x$loglik)+c(-10,1)
     )
axis(side=1,at=c(0.005,0.01,0.02,0.05,0.1,0.2,0.5))
axis(side=2)
lines(loglik~sigSE,data=nd,col=line.color)
abline(h=cutoff,lty='33')
abline(v=conf.int,lty='63')

plot.window(xlim=c(0.005,0.5),ylim=c(0,20))
lines(IP~sigSE,data=nd,lwd=2,col=IPcol,lty=IPlty)
lines(LP~sigSE,data=nd,lwd=2,col=LPcol,lty=LPlty)
axis(side=4)

plot.window(xlim=c(1,10),ylim=c(0,1))
text(10^(0.1),0.8,"Hastings",pos=3)

par(op)
```


---------------------------------------

#### Reporting rate

```{r report-rate,echo=FALSE,results="hide"}  
load("twentycities.rda")
readRDS("He2010_mles.rds") %>%
  subset(select=c(town,rho)) -> est.rho

demog %>%
  subset(year==1950,select=c(town,pop)) -> pop

measles %>%
  mutate(year=as.integer(format(date,"%Y"))) %>%
  ddply(~town+year,summarize,cases=sum(cases)) %>%
  join(demog,by=c("town","year")) %>%
  ddply(~town,summarize,
        cases=cumsum(cases),
        births=cumsum(births)) -> m

# m %>% ggplot(aes(x=births,y=cases,group=town))+
#   geom_point()+
#   geom_smooth(method="lm")+
#   facet_wrap(~town,ncol=4,scales="free")

m %>% ddply(~town,summarize,slope=coef(lm(cases~births))[2]) %>%
  join(pop,by='town') %>%
  join(est.rho,by='town') %>%
  melt(id=c("town","pop")) %>%
  mutate(variable=mapvalues(variable,from=c("slope","rho"),
                            to=c("regression","model"))) %>%
  ggplot(aes(x=town,y=value,shape=variable,group=town))+
  geom_point(size=3)+
  geom_line(alpha=0.5)+
  labs(x="",y="estimated reporting rate",
       variable="estimate")+
  theme(axis.text.x=element_text(angle=90,hjust=1))
```

---------------------------------------

#### Cohort effect

```{r cohort-effect,echo=FALSE,results="hide"}
best <- read.csv('data/cohort.csv',row.names=1)

op <- par(
          font=2,
          fig=c(0,1,0,1),
          mar=c(4,4,4,4),
          bty='l'
          )
plot.new()
mtext(side=2,line=2.5,text="profile log likelihood",adj=0.5)
mtext(side=1,line=2,text="cohort entry fraction",adj=0.5)

x <- best[grep('London',rownames(best)),]
fit <- loess(loglik~cohort,data=x,span=0.7)
nd <- data.frame(cohort=with(x,seq(from=min(cohort),to=max(cohort),length=100)))
nd$loglik <- predict(fit,newdata=nd)
cutoff <- max(nd$loglik,na.rm=T)-0.5*qchisq(p=0.95,df=1)
conf.int <- range(nd$cohort[nd$loglik>cutoff],na.rm=T)
par(fig=c(0,1,0.5,1),mar=c(0.5,4,4,4),new=T)
plot(
     loglik~cohort,
     data=x,
     font=2,
     bty='l',
     ann=F,
     xaxt='n',
     xlim=c(0,1),
     ylim=max(x$loglik)+c(-10,1)
     )
axis(side=1,at=seq(0,1,by=0.2),labels=F)
lines(loglik~cohort,data=nd,col=line.color)
abline(h=cutoff,lty='33')
abline(v=conf.int,lty='63')
text(0.1,cutoff,"London",pos=3)

x <- best[grep('Hastings',rownames(best)),]
fit <- loess(loglik~cohort,data=x,span=0.7)
nd <- data.frame(cohort=with(x,seq(from=min(cohort),to=max(cohort),length=100)))
nd$loglik <- predict(fit,newdata=nd)
cutoff <- max(nd$loglik,na.rm=T)-0.5*qchisq(p=0.95,df=1)
conf.int <- range(nd$cohort[nd$loglik>cutoff],na.rm=T)
par(fig=c(0,1,0,0.5),mar=c(4,4,0.5,4),new=T)
plot(
     loglik~cohort,
     data=x,
     font=2,
     bty='l',
     ann=F,
     xaxt='n',
     xlim=c(0,1),
     ylim=max(x$loglik)+c(-10,1)
     )
axis(side=1,at=seq(0,1,by=0.2))
lines(loglik~cohort,data=nd,col=line.color)
abline(h=cutoff,lty='33')
abline(v=conf.int,lty='63')
text(0.1,cutoff,"Hastings",pos=1)
par(op)
```

---------------------------------------

#### $R_0$

```{r R0,echo=FALSE,results="hide"}
best <- read.csv('data/R0profile.csv',row.names=1)

op <- par(
          font=2,
          fig=c(0,1,0,1),
          mar=c(4,4,4,4),
          bty='l'
          )
plot.new()
mtext(side=2,line=2.5,text="profile log likelihood",adj=0.5)
mtext(side=1,line=2,text=expression(R[0]),adj=0.5)

x <- best[grep('London',rownames(best)),]
fit <- loess(loglik~R0,data=x,span=0.7)
nd <- data.frame(R0=with(x,seq(from=min(R0),to=max(R0),length=100)))
nd$loglik <- predict(fit,newdata=nd)
cutoff <- max(nd$loglik,na.rm=T)-0.5*qchisq(p=0.95,df=1)
conf.int <- range(nd$R0[nd$loglik>cutoff],na.rm=T)
par(fig=c(0,1,0.5,1),mar=c(0.5,4,4,4),new=T)
plot(
     loglik~R0,
     data=x,
     font=2,
     bty='l',
     ann=F,
     xaxt='n',
     xlim=c(10,100),
     ylim=max(x$loglik)+c(-10,1)
     )
axis(side=1,at=seq(10,100,by=30),labels=F)
lines(loglik~R0,data=nd,col=line.color)
abline(h=cutoff,lty='33')
abline(v=conf.int,lty='63')
text(90,max(x$loglik),"London")

x <- best[grep('Hastings',rownames(best)),]
fit <- loess(loglik~R0,data=x,span=0.7)
nd <- data.frame(R0=with(x,seq(from=min(R0),to=max(R0),length=100)))
nd$loglik <- predict(fit,newdata=nd)
cutoff <- max(nd$loglik,na.rm=T)-0.5*qchisq(p=0.95,df=1)
conf.int <- range(nd$R0[nd$loglik>cutoff],na.rm=T)
par(fig=c(0,1,0,0.5),mar=c(4,4,0.5,4),new=T)
plot(
     loglik~R0,
     data=x,
     font=2,
     bty='l',
     ann=F,
     xaxt='n',
     xlim=c(10,100),
     ylim=max(x$loglik)+c(-10,1)
     )
axis(side=1,at=seq(10,100,by=30))
lines(loglik~R0,data=nd,col=line.color)
abline(h=cutoff,lty='33')
abline(v=conf.int,lty='63')
text(90,max(x$loglik),"Hastings")
par(op)
```


---------------------------------------

#### Birth delay

```{r delay,eval=TRUE,echo=FALSE,results="hide"}

x <- read.csv('data/delay.csv',row.names=1)
plot(
     x$delay,
     x$loglik,
     type='b',
     xlab=expression(paste(tau,' (yr)')),
     ylab='profile log likelihood'
     )

```


---------------------------------------

#### Predicted vs observed critical community size

```{r fadeouts,echo=FALSE,results="hide"}

op <- par(
          font=2,
          fig=c(0,1,0,1),
          mar=c(4,4,4,4),
          bty='l'
          )
ccssim <- read.csv('data/ccssim.csv',comment.char='#')
ccsdata <- read.csv('data/fadeouts_954.csv',row.names=1,comment.char='#')
plot(
     prop.fadeout~mean.pop,
     data=ccsdata,
     bty='l',
     log='x',
     ann=F,
     pch=20,
     xlim=range(ccssim$pop),
     ylim=c(0,1)
     )
lines(prop.fadeout~pop,data=ccssim,lwd=3,col=line.color)
mtext(side=1,line=3,text='community size')
mtext(side=2,line=3,text='proportion of weeks without cases')
par(op)
```

---------------------------------------


## Practicum

### Preliminaries

To get started, we must install `pomp` if it is not already installed.
The following commands install `pomp` from source (on github).
```{r pomp-install,eval=FALSE}
require(devtools)
install_github("kingaa/pomp")
```
If we were to run into trouble in the above, we would consult the [package website](http://kingaa.github.io/pomp/install.html).

Now we'll load the packages we'll need, and set the random seed, to allow reproducibility.
```{r prelims,cache=FALSE}
set.seed(594709947L)
require(ggplot2)
theme_set(theme_bw())
require(plyr)
require(reshape2)
require(magrittr)
require(pomp)
stopifnot(packageVersion("pomp")>="0.70-1")
```

### Data and covariates

Now we'll load the data and covariates.
The data are measles reports from 20 cities in England and Wales.
We also have information on the population sizes and birth-rates in these cities;
we'll treat these variables as covariates.

```{r load-data}
baseurl <- "http://kinglab.eeb.lsa.umich.edu/SBIED/"
download.file(paste0(baseurl,"data/twentycities.rda"),destfile="./twentycities.rda")
load("twentycities.rda")
measles %>% 
  mutate(year=as.integer(format(date,"%Y"))) %>%
  subset(town=="London" & year>=1950 & year<1964) %>%
  mutate(time=(julian(date,origin=as.Date("1950-01-01")))/365.25+1950) %>%
  subset(time>1950 & time<1964, select=c(time,cases)) -> dat
demog %>% subset(town=="London",select=-town) -> demog
```

Let's plot the data and covariates.

```{r data-plot}
dat %>% ggplot(aes(x=time,y=cases))+geom_line()
demog %>% melt(id="year") %>%
  ggplot(aes(x=year,y=value))+geom_point()+
  facet_wrap(~variable,ncol=1,scales="free_y")
```


```{r prep-covariates}
demog %>% 
  summarize(
    time=seq(from=min(year),to=max(year),by=1/12),
    pop=predict(smooth.spline(x=year,y=pop),x=time)$y,
    birthrate=predict(smooth.spline(x=year+0.5,y=births),x=time-4)$y
    ) -> covar
```
```{r covarplot}
plot(pop~time,data=covar,type='l')
points(pop~year,data=demog)
plot(birthrate~time,data=covar,type='l')
points(births~year,data=demog)
plot(birthrate~I(time-4),data=covar,type='l')
points(births~I(year+0.5),data=demog)
```

### The partially observed Markov process model

#### The (unobserved) process model

Let's evaluate the hypothesis that these data were generated by an SEIR model.
The SEIR model is a compartmental model that, diagrammatically, looks as follows.

```{r seir-diagram,echo=FALSE,cache=FALSE}
require(DiagrammeR)
DiagrammeR("digraph SEIR {
  graph [rankdir=TD, overlap=false, fontsize = 10]
  node[shape=egg, label='births'] b;
  subgraph {
    rank=same;
    node[shape=oval, label='S'] S;
    node[shape=oval, label='E'] E;
    node[shape=oval, label='I'] I;
    node[shape=oval, label='R'] R;
    S->E E->I I->R
  }
  node[shape=diamond, label='dead'] d;
  b->S
  {S E I R}->d
   }",type="grViz",engine="dot",height=300,width=500)
```
$b = \text{births}$  
$S = \text{susceptibles}$  
$E = \text{exposed, incubating}$  
$I = \text{infectious}$  
$R = \text{recovered}$  

We require a simulator for this model.
The following implements a simulator.

```{r rprocess}
rproc <- Csnippet("
  double beta, br, seas, foi, dw, births;
  double rate[6], trans[6];
  
  // cohort effect
  if (fabs(t-floor(t)-251.0/365.0) < 0.5*dt) 
    br = cohort*birthrate/dt + (1-cohort)*birthrate;
  else 
  	br = (1.0-cohort)*birthrate;

  // term-time seasonality
  t = (t-floor(t))*365.25;
  if ((t>=7&&t<=100) || (t>=115&&t<=199) || (t>=252&&t<=300) || (t>=308&&t<=356))
      seas = 1.0+amplitude*0.2411/0.7589;
    else
      seas = 1.0-amplitude;

  // transmission rate
  beta = R0*seas*(1.0-exp(-(gamma+mu)*dt))/dt;
  // force of infection
  foi = beta*pow(I+iota,alpha)/pop;
  // white noise (extrademographic stochasticity)
  dw = rgammawn(sigmaSE,dt);

  rate[0] = dw*foi/dt;  //infection rate (stochastic)
  rate[1] = mu;			    // natural S death
  rate[2] = sigma;		  // rate of ending of latent stage
  rate[3] = mu;			    // natural E death
  rate[4] = gamma;		  // recovery
  rate[5] = mu;			    // natural I death

  // Poisson births
  births = rpois(br*dt);
  
  // transitions between classes
  reulermultinom(2,S,&rate[0],dt,&trans[0]);
  reulermultinom(2,E,&rate[2],dt,&trans[2]);
  reulermultinom(2,I,&rate[4],dt,&trans[4]);

  S += births   - trans[0] - trans[1];
  E += trans[0] - trans[2] - trans[3];
  I += trans[2] - trans[4] - trans[5];
  R = pop - S - E - I;
  W += (dw - dt)/sigmaSE;  // standardized i.i.d. white noise
  C += trans[4];           // true incidence
")
```

In the above, $C$ represents the true incidence, i.e., the number of new infections occurring over an interval.
Since recognized measles infections are quarantined, we argue that most infection occurs before case recognition so that true incidence is a measure of the number of individuals progressing from the I to the R compartment in a given interval.

We complete the process model definition by specifying the distribution of initial unobserved states.
The following codes assume that the fraction of the population in each of the four compartments is known.

```{r initializer}
initlz <- Csnippet("
  double m = pop/(S_0+E_0+I_0+R_0);
  S = nearbyint(m*S_0);
  E = nearbyint(m*E_0);
  I = nearbyint(m*I_0);
  R = nearbyint(m*R_0);
  W = 0;
  C = 0;
")
```


#### The measurement model

We'll model both under-reporting and measurement error.
We want $\mathbb{E}[\text{cases}|C] = \rho\,C$, where $C$ is the true incidence and $0<\rho<1$ is the reporting efficiency.
We'll also assume that $\mathrm{Var}[\text{cases}|C] = \rho\,(1-\rho)\,C + (\psi\,\rho\,C)^2$, where $\psi$ quantifies overdispersion.
Note that when $\psi=0$, the variance-mean relation is that of the binomial distribution.
To be specific, we'll choose
$\text{cases|C} \sim f(\cdot|\rho,\psi,C)$,
where $$f(c|\rho,\psi,C) = \Phi(c+\tfrac{1}{2},\rho\,C,\rho\,(1-\rho)\,C+(\psi\,\rho\,C)^2)-\Phi(c-\tfrac{1}{2},\rho\,C,\rho\,(1-\rho)\,C+(\psi\,\rho\,C)^2),$$
where $\Phi(x,\mu,\sigma^2)$ is the c.d.f. of the normal distribution with mean $\mu$ and variance $\sigma^2$.

The following computes $\mathbb{P}[\text{cases}|C]$.

```{r dmeasure}
dmeas <- Csnippet("
  double m = rho*C;
  double v = m*(1.0-rho+psi*psi*m);
  double tol = 1.0e-18;
  if (cases > 0.0) {
	  lik = pnorm(cases+0.5,m,sqrt(v)+tol,1,0)-pnorm(cases-0.5,m,sqrt(v)+tol,1,0)+tol;
  } else {
    lik = pnorm(cases+0.5,m,sqrt(v)+tol,1,0)+tol;
  }
")
```

The following codes simulate $\text{cases} | C$.

```{r rmeasure}
rmeas <- Csnippet("
  double m = rho*C;
  double v = m*(1.0-rho+psi*psi*m);
  double tol = 1.0e-18;
  cases = rnorm(m,sqrt(v)+tol);
  if (cases > 0.0) {
    cases = nearbyint(cases);
  } else {
    cases = 0.0;
  }
")
```

#### Constructing the `pomp` object

We put all the model components together with the data in a call to `pomp`:

```{r pomp-construction}
dat %>% 
  pomp(t0=with(dat,2*time[1]-time[2]),
       time="time",
       rprocess=euler.sim(rproc,delta.t=1/365.25),
       initializer=initlz,
       dmeasure=dmeas,
       rmeasure=rmeas,
       covar=covar,
       tcovar="time",
       zeronames=c("C","W"),
       statenames=c("S","E","I","R","C","W"),
       paramnames=c("R0","mu","sigma","gamma","alpha","iota",
                    "rho","sigmaSE","psi","cohort","amplitude",
                    "S_0","E_0","I_0","R_0")
       ) -> m1
```

The following codes plot the data and covariates together.

```{r plot-pomp}
m1 %>% as.data.frame() %>% 
  melt(id="time") %>%
  ggplot(aes(x=time,y=value))+
  geom_line()+
  facet_grid(variable~.,scales="free_y")
```

@He2010 estimated the parameters of this model.
The following attaches the

```{r mle}
readRDS("He2010_mles.rds") %>% 
  subset(town=="London") -> mle
paramnames <- c("R0","mu","sigma","gamma","alpha","iota",
                "rho","sigmaSE","psi","cohort","amplitude",
                "S_0","E_0","I_0","R_0")
theta <- unlist(mle[paramnames])
kable(t(mle))
```

Verify that we get the same likelihood as @He2010.

```{r pfilter1}
require(foreach)
require(doMC)
registerDoMC()

set.seed(998468235L,kind="L'Ecuyer")
mcopts <- list(preschedule=FALSE,set.seed=TRUE)
paropts <- list(.options.multicore=mcopts)

foreach(i=1:4,
        .packages="pomp",
        .options.multicore=mcopts) %dopar% {
  pfilter(m1,Np=10000,params=theta)
} -> pfs
logmeanexp(sapply(pfs,logLik),se=TRUE)
```

Simulations at the MLE.

```{r sims1,fig.height=8}
m1 %>% 
  simulate(params=theta,nsim=10,as.data.frame=TRUE,include.data=TRUE) %>%
  ggplot(aes(x=time,y=cases,group=sim,color=(sim=="data")))+
  guides(color=FALSE)+
  geom_line()+facet_wrap(~sim,ncol=2)
```
```{r sims2}
m1 %>% 
  simulate(params=theta,nsim=100,as.data.frame=TRUE,include.data=TRUE) %>%
  subset(select=c(time,sim,cases)) %>%
  mutate(data=sim=="data") %>%
  ddply(~time+data,summarize,
        p=c(0.05,0.5,0.95),q=quantile(cases,prob=p,names=FALSE)) %>%
  mutate(p=mapvalues(p,from=c(0.05,0.5,0.95),to=c("lo","med","hi")),
         data=mapvalues(data,from=c(TRUE,FALSE),to=c("data","simulation"))) %>%
  dcast(time+data~p,value.var='q') %>%
  ggplot(aes(x=time,y=med,color=data,fill=data,ymin=lo,ymax=hi))+
  geom_ribbon(alpha=0.2)
```

#### Parameter transformations

The parameters are constrained to be positive, and some of them are constrained to lie between $0$ and $1$.
We can turn the likelihood maximization problem into an unconstrained maximization problem by transforming the parameters.
The following Csnippets implement such a transformation and its inverse.

```{r transforms}
toEst <- Csnippet("
  Tmu = log(mu);
  Tsigma = log(sigma);
  Tgamma = log(gamma);
  Talpha = log(alpha);
  Tiota = log(iota);
  Trho = logit(rho);
  Tcohort = logit(cohort);
  Tamplitude = logit(amplitude);
  TsigmaSE = log(sigmaSE);
  Tpsi = log(psi);
  TR0 = log(R0);
  to_log_barycentric (&TS_0, &S_0, 4);
")

fromEst <- Csnippet("
  Tmu = exp(mu);
  Tsigma = exp(sigma);
  Tgamma = exp(gamma);
  Talpha = exp(alpha);
  Tiota = exp(iota);
  Trho = expit(rho);
  Tcohort = expit(cohort);
  Tamplitude = expit(amplitude);
  TsigmaSE = exp(sigmaSE);
  Tpsi = exp(psi);
  TR0 = exp(R0);
  from_log_barycentric (&TS_0, &S_0, 4);
")


pomp(m1,toEstimationScale=toEst,
     fromEstimationScale=fromEst,
     statenames=c("S","E","I","R","C","W"),
     paramnames=c("R0","mu","sigma","gamma","alpha","iota",
                  "rho","sigmaSE","psi","cohort","amplitude",
                  "S_0","E_0","I_0","R_0")) -> m1
```


## References
